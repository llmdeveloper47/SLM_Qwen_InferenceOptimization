# Week 1 Workflow Diagram

## ğŸ“Š Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Week 1: Baseline Profiling                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HuggingFace Hub â”‚
â”‚  amazon_test     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  01_download_data.py                         â”‚
â”‚  â€¢ Downloads dataset                         â”‚
â”‚  â€¢ Converts to CSV                           â”‚
â”‚  â€¢ Creates label mappings                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  data/                                       â”‚
â”‚  â”œâ”€â”€ val_df.csv (369K samples)              â”‚
â”‚  â””â”€â”€ label_mappings.json (23 labels)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚                                      â”‚
         â–¼                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  HuggingFace Hub â”‚              â”‚  Model Loading      â”‚
â”‚  intent-class    â”‚              â”‚  â€¢ Load from HF     â”‚
â”‚  -qwen model     â”‚              â”‚  â€¢ Setup tokenizer  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚  â€¢ Move to GPU      â”‚
         â”‚                        â”‚  â€¢ Set eval mode    â”‚
         â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                                   â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  02_baseline_inference.py         â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚ Profile Multiple Batch Sizesâ”‚  â”‚
         â”‚  â”‚  â€¢ BS: 1, 4, 8, 16, 32, 64  â”‚  â”‚
         â”‚  â”‚  â€¢ 10 runs each             â”‚  â”‚
         â”‚  â”‚  â€¢ Measure:                 â”‚  â”‚
         â”‚  â”‚    - Latency                â”‚  â”‚
         â”‚  â”‚    - Throughput             â”‚  â”‚
         â”‚  â”‚    - Memory                 â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
         â”‚  â”‚ Full Dataset Evaluation     â”‚  â”‚
         â”‚  â”‚  â€¢ All 369K samples         â”‚  â”‚
         â”‚  â”‚  â€¢ Optimal batch size       â”‚  â”‚
         â”‚  â”‚  â€¢ Calculate accuracy       â”‚  â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â–¼
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  results/                          â”‚
         â”‚  â”œâ”€â”€ baseline_metrics.json         â”‚
         â”‚  â””â”€â”€ detailed_metrics.csv          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                  â”‚
                    â–¼                  â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 03_detailed_         â”‚  â”‚ 04_visualize_          â”‚
    â”‚    profiling.py      â”‚  â”‚    results.py          â”‚
    â”‚                      â”‚  â”‚                        â”‚
    â”‚ â€¢ PyTorch Profiler   â”‚  â”‚ â€¢ Batch size plots     â”‚
    â”‚ â€¢ Operation timing   â”‚  â”‚ â€¢ Metrics heatmap      â”‚
    â”‚ â€¢ Memory tracking    â”‚  â”‚ â€¢ Summary report       â”‚
    â”‚ â€¢ Stack traces       â”‚  â”‚ â€¢ Analysis charts      â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                       â”‚
               â–¼                       â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ profiler_traces/    â”‚  â”‚ plots/               â”‚
    â”‚ â”œâ”€â”€ trace.json      â”‚  â”‚ â”œâ”€â”€ batch_size_      â”‚
    â”‚ â””â”€â”€ stacks.txt      â”‚  â”‚ â”‚   comparison.png   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â””â”€â”€ metrics_         â”‚
                             â”‚     heatmap.png      â”‚
                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”„ Execution Flow

```
run_week1.py (Main Orchestrator)
    â”‚
    â”œâ”€â–º [Step 1] 01_download_data.py
    â”‚   â””â”€â–º Downloads HuggingFace dataset
    â”‚       Creates val_df.csv
    â”‚       Creates label mappings
    â”‚       Time: ~10 minutes
    â”‚
    â”œâ”€â–º [Step 2] 02_baseline_inference.py
    â”‚   â”œâ”€â–º Load model
    â”‚   â”œâ”€â–º Profile batch sizes: [1, 4, 8, 16, 32, 64]
    â”‚   â”‚   â””â”€â–º For each batch size:
    â”‚   â”‚       â”œâ”€â–º Warmup (3 runs)
    â”‚   â”‚       â”œâ”€â–º Measure (10 runs)
    â”‚   â”‚       â””â”€â–º Aggregate metrics
    â”‚   â”œâ”€â–º Full dataset inference
    â”‚   â””â”€â–º Calculate accuracy
    â”‚   Time: ~15 minutes
    â”‚
    â”œâ”€â–º [Step 3] 03_detailed_profiling.py (Optional)
    â”‚   â”œâ”€â–º PyTorch profiler
    â”‚   â”œâ”€â–º Chrome trace generation
    â”‚   â””â”€â–º Stack analysis
    â”‚   Time: ~10 minutes
    â”‚
    â””â”€â–º [Step 4] 04_visualize_results.py
        â”œâ”€â–º Load metrics
        â”œâ”€â–º Generate 6-panel plot
        â”œâ”€â–º Create heatmap
        â””â”€â–º Write summary report
        Time: ~2 minutes

Total: 30-40 minutes
```

---

## ğŸ§© Module Dependencies

```
run_week1.py
    â”‚
    â”œâ”€â–º utils/config_loader.py
    â”‚   â””â”€â–º configs/config.yaml
    â”‚
    â”œâ”€â–º utils/model_utils.py
    â”‚   â”œâ”€â–º torch
    â”‚   â””â”€â–º transformers
    â”‚
    â”œâ”€â–º utils/metrics.py
    â”‚   â”œâ”€â–º torch
    â”‚   â”œâ”€â–º psutil
    â”‚   â””â”€â–º pynvml (optional)
    â”‚
    â””â”€â–º utils/profiler.py
        â”œâ”€â–º utils/metrics.py
        â”œâ”€â–º torch
        â””â”€â–º sklearn (for accuracy)

All scripts import from utils/
All utils are independent and reusable
```

---

## ğŸ“ˆ Metrics Collection Flow

```
Start Measurement
    â”‚
    â”œâ”€â–º Record start time
    â”œâ”€â–º Record CPU memory (psutil)
    â”œâ”€â–º Record GPU memory (torch.cuda)
    â””â”€â–º Record GPU utilization (pynvml)
    â”‚
    â–¼
Run Inference
    â”‚
    â”œâ”€â–º Tokenize text
    â”œâ”€â–º Move to GPU
    â”œâ”€â–º Model forward pass
    â”œâ”€â–º Get predictions
    â””â”€â–º Sync GPU (torch.cuda.synchronize)
    â”‚
    â–¼
End Measurement
    â”‚
    â”œâ”€â–º Record end time
    â”œâ”€â–º Calculate elapsed time
    â”œâ”€â–º Record final memory
    â””â”€â–º Calculate metrics:
        â”œâ”€â–º Latency = elapsed / samples
        â”œâ”€â–º Throughput = samples / elapsed
        â”œâ”€â–º Memory = final - start
        â””â”€â–º Utilization = average
    â”‚
    â–¼
Aggregate Results (10 runs)
    â”‚
    â”œâ”€â–º Calculate mean
    â”œâ”€â–º Calculate std deviation
    â”œâ”€â–º Calculate min/max
    â””â”€â–º Calculate median
    â”‚
    â–¼
Save Results
    â”‚
    â”œâ”€â–º JSON (baseline_metrics.json)
    â”œâ”€â–º CSV (detailed_metrics.csv)
    â””â”€â–º TXT (baseline_summary_report.txt)
```

---

## ğŸ¯ Optimization Journey

```
Week 1 (Baseline)
    â†“
Measure current performance
â€¢ Latency: ~20ms/sample
â€¢ Throughput: ~100 samples/sec
â€¢ Memory: ~4GB GPU
    â†“
Identify bottlenecks
â€¢ Matrix multiplications (slow)
â€¢ Attention layers (memory)
â€¢ Data transfer (I/O)
    â†“
Document baseline
â€¢ All metrics saved
â€¢ Bottlenecks identified
â€¢ Optimal config found
    â†“
Week 2 (Optimization)
â€¢ Apply quantization
â€¢ Reduce precision
â€¢ Optimize batch size
    â†“
Compare improvements
â€¢ 2-3x faster
â€¢ 50% less memory
â€¢ <1% accuracy loss
```

---

## ğŸ” Profiling Methodology

### Why Multiple Runs?
- **Warmup (3 runs)**: Eliminate CUDA compilation, cache effects
- **Measurement (10 runs)**: Statistical significance
- **Aggregation**: Mean Â± std for reliability

### Why Multiple Batch Sizes?
- **Small (1-4)**: Baseline latency, minimal memory
- **Medium (8-16)**: Balanced performance
- **Large (32-64)**: Maximum throughput
- **Analysis**: Find sweet spot

### Why Full Dataset?
- **Real-world performance**: Not just sample
- **Accuracy verification**: Ensure model works
- **End-to-end timing**: Complete pipeline
- **Production estimate**: Actual deployment metrics

---

## ğŸ Included Utilities

### Testing & Validation
- `test_setup.py` - Verify environment
- `00_test_model_loading.py` - Test model
- `validate_dataset.py` - Validate data
- `example_interactive.py` - Quick profiling

### Automation
- `setup_environment.sh` - One-command setup
- `run_week1.py` - One-command execution
- `show_structure.py` - View directory tree

### Documentation
- 7 markdown files covering all aspects
- Every script has docstrings
- Every function documented
- Examples included

---

## ğŸ“¦ Deliverables After Week 1

You will have:

1. **Quantitative Metrics**
   - Exact latency measurements
   - Throughput numbers
   - Memory usage data
   - Model size statistics

2. **Qualitative Analysis**
   - Bottleneck identification
   - Optimization opportunities
   - Configuration recommendations
   - Week 2 preparation

3. **Artifacts**
   - Metrics files (JSON, CSV)
   - Visualization plots (PNG)
   - Profiler traces (Chrome)
   - Summary report (TXT)

4. **Knowledge**
   - Current performance understood
   - Bottlenecks identified
   - Baseline established
   - Ready for optimization

---

## ğŸ Your Action Items

### Right Now:
1. Read `START_HERE.md` (2 min)
2. Upload files to RunPod
3. Follow `RUNPOD_SETUP.md`

### On RunPod:
1. `pip install -r setup/requirements.txt`
2. `python test_setup.py`
3. `python run_week1.py`

### After Completion:
1. Review `results/baseline_summary_report.txt`
2. Analyze `results/plots/`
3. Download results
4. Document findings for Week 2

---

**Everything is ready!**

**Next**: Upload to RunPod and run `python run_week1.py`

**Documentation**: All questions answered in markdown files

**Support**: Detailed troubleshooting in `week1_instructions.md`

---

Good luck with Week 1! ğŸš€

